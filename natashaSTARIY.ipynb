{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b17084-4784-4f47-987a-e7412a2ed5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    MorphVocab,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "from razdel import tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b86952-036a-4e17-b620-45b7ab2b7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    \"\"\"Лемматизация Natasha, работает на Python 3.11+\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    \n",
    "    # нормализация слов\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    \n",
    "    lemmas = [token.lemma for token in doc.tokens]\n",
    "    return \" \".join(lemmas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fba4f2-1c5c-4a5e-9f41-8304bf9d262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== НАЧИНАЮ ПРЕДОБРАБОТКУ (Natasha) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 0it [00:02, ?it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.06 MiB for an array with shape (7, 40, 330, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== НАЧИНАЮ ПРЕДОБРАБОТКУ (Natasha) ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m tqdm(df_iter, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(preprocess)\n\u001b[0;32m      8\u001b[0m     processed_chunks\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[0;32m     10\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(processed_chunks)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     10\u001b[0m doc \u001b[38;5;241m=\u001b[39m Doc(text)\n\u001b[0;32m     11\u001b[0m doc\u001b[38;5;241m.\u001b[39msegment(segmenter)\n\u001b[1;32m---> 12\u001b[0m doc\u001b[38;5;241m.\u001b[39mtag_morph(morph_tagger)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# нормализация слов\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mtokens:\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\natasha\\doc.py:136\u001b[0m, in \u001b[0;36mDoc.tag_morph\u001b[1;34m(self, tagger)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtag_morph\u001b[39m(\u001b[38;5;28mself\u001b[39m, tagger):\n\u001b[1;32m--> 136\u001b[0m     tag_morph_doc(\u001b[38;5;28mself\u001b[39m, tagger)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\natasha\\doc.py:212\u001b[0m, in \u001b[0;36mtag_morph_doc\u001b[1;34m(doc, tagger)\u001b[0m\n\u001b[0;32m    210\u001b[0m chunk \u001b[38;5;241m=\u001b[39m [sent_words(_) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents]\n\u001b[0;32m    211\u001b[0m markups \u001b[38;5;241m=\u001b[39m tagger\u001b[38;5;241m.\u001b[39mmap(chunk)\n\u001b[1;32m--> 212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent, markup \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(doc\u001b[38;5;241m.\u001b[39msents, markups):\n\u001b[0;32m    213\u001b[0m     inject_morph(sent\u001b[38;5;241m.\u001b[39mtokens, markup\u001b[38;5;241m.\u001b[39mtokens)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\natasha\\morph\\tagger.py:75\u001b[0m, in \u001b[0;36mMorphTagger.map\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, items):\n\u001b[0;32m     74\u001b[0m     markups \u001b[38;5;241m=\u001b[39m SlovnetMorph\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m, items)\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m markup \u001b[38;5;129;01min\u001b[39;00m markups:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m adapt_markup(markup)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\slovnet\\api.py:35\u001b[0m, in \u001b[0;36mAPI.map\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, items):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chop(items, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size):\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(chunk)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\slovnet\\exec\\infer.py:66\u001b[0m, in \u001b[0;36mMorphInfer.__call__\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m     63\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess(inputs)\n\u001b[0;32m     64\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(preds)\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(items, preds):\n\u001b[0;32m     67\u001b[0m     tuples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(item, pred)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m MorphMarkup\u001b[38;5;241m.\u001b[39mfrom_tuples(tuples)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\slovnet\\exec\\infer.py:28\u001b[0m, in \u001b[0;36mTagDecoder.__call__\u001b[1;34m(self, preds)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds):\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m preds:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags_vocab\u001b[38;5;241m.\u001b[39mdecode(_) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m pred]\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\slovnet\\exec\\infer.py:57\u001b[0m, in \u001b[0;36mMorphInfer.process\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m---> 57\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mword_id, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape_id, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mask)\n\u001b[0;32m     58\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;241m.\u001b[39mdecode(pred)\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m split_masked(pred, \u001b[38;5;241m~\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mask)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\slovnet\\exec\\model.py:325\u001b[0m, in \u001b[0;36mTag.__call__\u001b[1;34m(self, word_id, shape_id, pad_mask)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, word_id, shape_id, pad_mask):\n\u001b[0;32m    324\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb(word_id, shape_id)\n\u001b[1;32m--> 325\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x, pad_mask)\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\slovnet\\exec\\model.py:282\u001b[0m, in \u001b[0;36mCNNEncoder.__call__\u001b[1;34m(self, input, mask)\u001b[0m\n\u001b[0;32m    279\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m layer(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    283\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28minput\u001b[39m[mask\u001b[38;5;241m.\u001b[39mrepeat(size, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\slovnet\\exec\\model.py:266\u001b[0m, in \u001b[0;36mCNNEncoderLayer.__call__\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m--> 266\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    267\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\slovnet\\exec\\model.py:106\u001b[0m, in \u001b[0;36mConv1d.__call__\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m windows \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray(\n\u001b[0;32m     99\u001b[0m     (batch_size, windows_count, in_dim, kernel_size),\n\u001b[0;32m    100\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    101\u001b[0m     buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m    102\u001b[0m     strides\u001b[38;5;241m=\u001b[39m(batch_stride, unit_stride, in_stride, seq_stride)\n\u001b[0;32m    103\u001b[0m )\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# conv\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m windows \u001b[38;5;241m=\u001b[39m windows\u001b[38;5;241m.\u001b[39mreshape(batch_size \u001b[38;5;241m*\u001b[39m windows_count, in_dim \u001b[38;5;241m*\u001b[39m kernel_size)\n\u001b[0;32m    107\u001b[0m weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mreshape(filters_count, in_dim \u001b[38;5;241m*\u001b[39m kernel_size)\n\u001b[0;32m    108\u001b[0m output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(windows, weight\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39marray\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.06 MiB for an array with shape (7, 40, 330, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "df_iter = pd.read_csv(\"train.csv\", chunksize=20000)\n",
    "\n",
    "processed_chunks = []\n",
    "\n",
    "print(\"=== НАЧИНАЮ ПРЕДОБРАБОТКУ (Natasha) ===\")\n",
    "for chunk in tqdm(df_iter, desc=\"Processing chunks\"):\n",
    "    chunk[\"clean_text\"] = chunk[\"text\"].apply(preprocess)\n",
    "    processed_chunks.append(chunk)\n",
    "\n",
    "train = pd.concat(processed_chunks)\n",
    "train.to_csv(\"train_clean.csv\", index=False)\n",
    "\n",
    "print(\"\\n=== ПРЕДОБРАБОТКА ЗАВЕРШЕНА ===\")\n",
    "print(\"Сохранено: train_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf30ab6-24a3-488b-9f7b-e6bf21964491",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_clean.csv\")\n",
    "\n",
    "X = train[\"clean_text\"]\n",
    "y = train[\"label\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcec466-019a-4f18-aca7-21db58ae7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ВЕКТОРИЗАЦИЯ TF-IDF ===\")\n",
    "\n",
    "X_train = X_train.fillna(\"\").astype(str)\n",
    "X_val = X_val.fillna(\"\").astype(str)\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,                # снижает шум\n",
    "    max_df=0.9, \n",
    ")\n",
    "\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_val_vec = tfidf.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c45aa8-9bc4-498d-9c89-1607b63a6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ОБУЧЕНИЕ МОДЕЛИ LinearSVC ===\")\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd5291-74ed-4df6-ac4e-4e05897afee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict(X_val_vec)\n",
    "score = f1_score(y_val, val_pred, average=\"macro\")\n",
    "\n",
    "print(\"\\n=== ОБУЧЕНИЕ ЗАВЕРШЕНО ===\")\n",
    "print(\"Macro-F1:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2cd339-5f15-49cb-9c38-074d907bbeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, \"sentiment_model.pkl\")\n",
    "joblib.dump(tfidf, \"tfidf.pkl\")\n",
    "\n",
    "print(\"\\n=== ФАЙЛЫ СОХРАНЕНЫ ===\")\n",
    "print(\"sentiment_model.pkl — обученная модель\")\n",
    "print(\"tfidf.pkl — TF-IDF векторизатор\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d70bd-1243-40ac-8140-32ceccbb78fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
