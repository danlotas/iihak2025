import torch
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
import pandas as pd
import numpy as np
import torch.nn.functional as F
from sklearn.metrics import f1_score
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# =====================================================
# üîß –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ü–û–î RENDER FREE
# =====================================================
torch.set_num_threads(1)  # —Å–∏–ª—å–Ω–æ —Å–Ω–∏–∂–∞–µ—Ç –Ω–∞–≥—Ä—É–∑–∫—É CPU
MODEL_PATH = "./bert_model"

# =====================================================
# üöÄ FASTAPI APP
# =====================================================
app = FastAPI()

# –†–∞–∑—Ä–µ—à–∞–µ–º —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =====================================================
# üì¶ –ü–û–î–ö–õ–Æ–ß–ê–ï–ú –°–¢–ê–¢–ò–ö–£ –ò index.html
# =====================================================

# –ú–æ–Ω—Ç–∏—Ä—É–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é frontend/ –∫–∞–∫ —Å—Ç–∞—Ç–∏–∫
app.mount("/static", StaticFiles(directory="frontend"), name="static")

# –û—Ç–¥–∞–µ–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
@app.get("/")
async def root():
    return FileResponse("frontend/index.html")


# =====================================================
# üìö –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ)
# =====================================================
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)

model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_PATH,
    low_cpu_mem_usage=True,
    torch_dtype=torch.float32
)

model.eval()


# =====================================================
# 1Ô∏è‚É£ API ‚Äî –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
# =====================================================
@app.post("/predict_text")
async def predict_text_api(text: str = Form(...)):

    tokens = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=256
    )

    with torch.no_grad():
        logits = model(**tokens).logits

    probs = F.softmax(logits, dim=1).numpy()[0]
    pred = int(np.argmax(probs))

    return {
        "prediction": pred,
        "probabilities": {
            "negative": float(probs[0]),
            "neutral": float(probs[1]),
            "positive": float(probs[2]),
        }
    }


# =====================================================
# 2Ô∏è‚É£ API ‚Äî –ø–∞–∫–µ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ CSV
# =====================================================
@app.post("/predict_csv")
async def predict_csv_api(file: UploadFile = File(...)):
    df = pd.read_csv(file.file)

    if "text" not in df.columns:
        return {"error": "CSV must contain 'text' column"}

    preds, negs, neuts, poss = [], [], [], []

    for t in df["text"]:
        tokens = tokenizer(
            str(t),
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=256
        )
        with torch.no_grad():
            logits = model(**tokens).logits

        probs = F.softmax(logits, dim=1).numpy()[0]

        preds.append(int(np.argmax(probs)))
        negs.append(float(probs[0]))
        neuts.append(float(probs[1]))
        poss.append(float(probs[2]))

    df["pred"] = preds
    df["prob_neg"] = negs
    df["prob_neu"] = neuts
    df["prob_pos"] = poss

    return df.to_dict(orient="records")


# =====================================================
# 3Ô∏è‚É£ API ‚Äî –≤–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø–æ CSV
# =====================================================
@app.post("/evaluate_csv")
async def evaluate_csv_api(file: UploadFile = File(...)):
    df = pd.read_csv(file.file)

    if "text" not in df.columns or "label" not in df.columns:
        return {"error": "CSV must contain 'text' and 'label'"}

    preds = []
    for t in df["text"]:
        tokens = tokenizer(
            str(t),
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=256
        )
        with torch.no_grad():
            logits = model(**tokens).logits

        preds.append(int(np.argmax(logits)))

    df["pred"] = preds

    macro_f1 = f1_score(df["label"], df["pred"], average="macro")

    return {"macro_f1": float(macro_f1)}
